"""
ğŸ“ æ¯æ—¥ç ”æŠ¥ - AIç»¼åˆåˆ†æ
"""
import streamlit as st
import json
import os
from datetime import datetime
import pandas as pd
import sys

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.data_fetcher import (
    get_major_indices, get_market_overview, get_industry_board,
    get_macro_data, get_style_data, get_cls_telegraph,
)
from utils.ai_analyzer import analyze_news_batch, generate_daily_report

st.set_page_config(page_title="æ¯æ—¥ç ”æŠ¥", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ æ¯æ—¥ç ”æŠ¥")
st.caption("AI ç»¼åˆåˆ†æ Â· å®è§‚åˆ¤æ–­ Â· é…ç½®å»ºè®® Â· æŠ•èµ„çº¿ç´¢")
st.divider()

# APIæ£€æŸ¥
api_key = ""
try:
    api_key = st.secrets.get("DEEPSEEK_API_KEY", "")
except Exception:
    pass
has_api = bool(api_key and not api_key.startswith("sk-xxxx"))

if not has_api:
    st.warning("""
âš ï¸ **æœªé…ç½® DeepSeek API Key** â€” ç ”æŠ¥éœ€è¦AIèƒ½åŠ›

1. æ³¨å†Œ [platform.deepseek.com](https://platform.deepseek.com/)
2. åˆ›å»º API Keyï¼Œå……å€¼10å…ƒ
3. Streamlit Cloud â†’ Settings â†’ Secrets æ·»åŠ ï¼š
```
DEEPSEEK_API_KEY = "sk-ä½ çš„å¯†é’¥"
```
    """)

# ç¼“å­˜
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "data")
os.makedirs(DATA_DIR, exist_ok=True)
today_file = os.path.join(DATA_DIR, f"report_{datetime.now().strftime('%Y%m%d')}.json")


def load_cache():
    if os.path.exists(today_file):
        with open(today_file, "r", encoding="utf-8") as f:
            return json.load(f)
    return None


def save_cache(data):
    with open(today_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)


cached = load_cache()
if cached:
    st.info(f"ğŸ“„ å·²æœ‰ä»Šæ—¥ç¼“å­˜æŠ¥å‘Šï¼ˆ{cached.get('time', '')}ï¼‰")

c1, c2 = st.columns(2)
with c1:
    gen_btn = st.button("ğŸš€ ç”Ÿæˆæ–°æŠ¥å‘Š", type="primary", use_container_width=True, disabled=not has_api)
with c2:
    load_btn = st.button("ğŸ“„ æŸ¥çœ‹ç¼“å­˜", use_container_width=True, disabled=not cached)

report = None

if gen_btn and has_api:
    progress = st.progress(0, "å‡†å¤‡ä¸­...")

    # é‡‡é›†
    progress.progress(10, "ğŸ“¡ é‡‡é›†è¡Œæƒ…...")
    idx_df = get_major_indices()
    overview = get_market_overview()
    style = get_style_data()
    macro = get_macro_data()
    ind_df = get_industry_board()

    progress.progress(30, "ğŸ“° é‡‡é›†èµ„è®¯...")
    news = get_cls_telegraph(50)

    progress.progress(50, "ğŸ¤– AIåˆ†æèµ„è®¯...")
    analyzed = analyze_news_batch(news)

    # æ„é€ æ‘˜è¦
    progress.progress(70, "ğŸ“ ç”ŸæˆæŠ¥å‘Š...")

    # å¸‚åœºæ‘˜è¦
    market_parts = ["## å¸‚åœºæ•°æ®"]
    if idx_df is not None and not idx_df.empty and "error" not in idx_df.columns:
        for _, r in idx_df.iterrows():
            chg = r.get("æ¶¨è·Œå¹…", 0)
            chg_str = f"{chg:+.2f}%" if pd.notna(chg) else ""
            market_parts.append(f"- {r.get('åç§°','')}: {r.get('æœ€æ–°ä»·','')} ({chg_str})")

    if overview and "error" not in overview:
        market_parts.append(f"\næ¶¨{overview.get('ä¸Šæ¶¨',0)} è·Œ{overview.get('ä¸‹è·Œ',0)} "
                            f"æ¶¨åœ{overview.get('æ¶¨åœ',0)} è·Œåœ{overview.get('è·Œåœ',0)} "
                            f"æˆäº¤{overview.get('æ€»æˆäº¤é¢äº¿',0)}äº¿")

    if style:
        market_parts.append(f"\né£æ ¼: {style.get('åå¥½','')} | "
                            f"æ²ªæ·±300 5æ—¥{style.get('æ²ªæ·±300_5æ—¥','')}% | "
                            f"ä¸­è¯1000 5æ—¥{style.get('ä¸­è¯1000_5æ—¥','')}%")

    if macro:
        market_parts.append("\nå®è§‚: " + " | ".join(f"{k}:{v}" for k, v in macro.items()))

    if ind_df is not None and not ind_df.empty:
        top5 = ind_df.head(5)
        if "æ¿å—åç§°" in top5.columns and "æ¶¨è·Œå¹…" in top5.columns:
            market_parts.append("\nè¡Œä¸šæ¶¨å¹…å‰5: " +
                                ", ".join(f"{r['æ¿å—åç§°']}({r['æ¶¨è·Œå¹…']:+.1f}%)" for _, r in top5.iterrows()))
        bot5 = ind_df.tail(5)
        if "æ¿å—åç§°" in bot5.columns and "æ¶¨è·Œå¹…" in bot5.columns:
            market_parts.append("è¡Œä¸šè·Œå¹…å‰5: " +
                                ", ".join(f"{r['æ¿å—åç§°']}({r['æ¶¨è·Œå¹…']:+.1f}%)" for _, r in bot5.iterrows()))

    market_text = "\n".join(market_parts)

    # èµ„è®¯æ‘˜è¦
    news_parts = ["## ä»Šæ—¥èµ„è®¯"]
    if analyzed:
        sents = [item.get("analysis", {}).get("sentiment", 0) for item in analyzed]
        avg = sum(sents) / len(sents) if sents else 0
        news_parts.append(f"å…±{len(analyzed)}æ¡, æ•´ä½“æƒ…ç»ª{avg:.2f}")

        sorted_news = sorted(analyzed, key=lambda x: x.get("analysis", {}).get("impact", 0), reverse=True)
        for item in sorted_news[:20]:
            a = item.get("analysis", {})
            s = a.get("sentiment", 0)
            emoji = "ğŸŸ¢" if s > 0.2 else ("ğŸ”´" if s < -0.2 else "âšª")
            secs = ",".join(a.get("sectors", []))
            news_parts.append(f"{emoji}[{a.get('category','')}] {item.get('title','')} | {s:+.2f} | {secs}")

    news_text = "\n".join(news_parts)

    # è°ƒç”¨AI
    report = generate_daily_report(market_text, news_text)

    progress.progress(90, "ğŸ’¾ ä¿å­˜...")
    save_cache({"time": datetime.now().strftime("%H:%M"), "report": report})

    progress.progress(100, "âœ… å®Œæˆ!")
    st.balloons()

elif load_btn and cached:
    report = cached.get("report", "")

# ============================================================
# å±•ç¤ºæŠ¥å‘Š
# ============================================================
if report:
    st.divider()

    st.markdown(f"""
<div style="padding:16px 20px; border-radius:10px;
background: linear-gradient(135deg, rgba(255,107,53,0.1), rgba(69,183,209,0.05));
border: 1px solid rgba(255,107,53,0.2); margin-bottom:20px;">
<h2 style="margin:0; color:#FF6B35;">å¯»æ˜Ÿå¸‚åœºæ—¥æŠ¥</h2>
<p style="margin:4px 0 0; color:#999;">{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')} Â· DeepSeek V3</p>
</div>""", unsafe_allow_html=True)

    st.markdown(report)

    st.divider()
    c1, c2 = st.columns(2)
    with c1:
        st.download_button("ğŸ“„ ä¸‹è½½ Markdown", report,
                           f"å¯»æ˜Ÿæ—¥æŠ¥_{datetime.now().strftime('%Y%m%d')}.md",
                           "text/markdown", use_container_width=True)
    with c2:
        st.download_button("ğŸ“ ä¸‹è½½ TXT",
                           report.replace("###", "").replace("**", ""),
                           f"å¯»æ˜Ÿæ—¥æŠ¥_{datetime.now().strftime('%Y%m%d')}.txt",
                           "text/plain", use_container_width=True)
else:
    if not gen_btn:
        st.markdown("""
### æŠ¥å‘Šå°†åŒ…å«ï¼š

| ç« èŠ‚ | å†…å®¹ | å¯¹åº”éœ€æ±‚ |
|------|------|----------|
| å®è§‚ç¯å¢ƒ | è‚¡å€ºå•†é…ç½®å€¾å‘ | å¤§ç±»èµ„äº§æ–¹å‘ |
| é£æ ¼ç ”åˆ¤ | å¤§å°ç›˜/æˆé•¿ä»·å€¼ | FOFé£æ ¼äº§å“å¢å‡é… |
| è¡Œä¸šæ¨è | TOP3è¡Œä¸š+å›é¿ | ETFé…ç½®+é€‰è‚¡æ–¹å‘ |
| FOFå»ºè®® | å„ç­–ç•¥å¢å‡é… | å¯»æ˜Ÿç»„åˆè°ƒæ•´ |
| ETFæ¨è | å…·ä½“ä»£ç +é€»è¾‘ | ETFæ›¿ä»£ä»“ä½ |
| ä¸ªè‚¡çº¿ç´¢ | æœºä¼š+å‚¬åŒ–å‰‚ | ä¸ªäººæŠ•èµ„ |
| é£é™©æç¤º | ä¸»è¦é£é™©ç‚¹ | é˜²å¾¡é…ç½® |

ğŸ‘† ç‚¹å‡» **ã€Œç”Ÿæˆæ–°æŠ¥å‘Šã€** å¼€å§‹
        """)

st.caption(f"å¯»æ˜Ÿé…ç½®è·Ÿè¸ªç³»ç»Ÿ Â· v1.0")
