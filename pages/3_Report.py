"""
ğŸ“ CIO æ—¥æŠ¥ V4 - FOF é…ç½®å†³ç­–ä¸­å¿ƒ
================================================================
V4: å…¨é‡æ•°æ®é©±åŠ¨ + æ•°æ®è´¨é‡å®¡è®¡ + æ¡¥æ°´å››ç»´æ¡†æ¶
================================================================
"""
import streamlit as st
import json
import os
from datetime import datetime
import sys

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.data_fetcher import (
    get_daily_data_pack, pack_market_text, pack_news_text,
    _tushare_available, get_sentiment_temperature,
)
from utils.ai_analyzer import generate_daily_report

st.set_page_config(page_title="CIO æ—¥æŠ¥", page_icon="ğŸ“", layout="wide")

if not st.session_state.get("authenticated"):
    st.warning("è¯·å…ˆç™»å½•")
    st.page_link("app.py", label="ğŸ” è¿”å›ç™»å½•", icon="ğŸ ")
    st.stop()

st.title("ğŸ“ å¯»æ˜Ÿ CIO æ—¥æŠ¥")
st.caption("AI å…¨é‡æ•°æ®é©±åŠ¨ Â· æ¡¥æ°´å››ç»´å®è§‚ Â· å¤§ç±»é…ç½® Â· FOFç­–ç•¥ Â· é£æ§é¢„æ¡ˆ")
st.divider()

# ============================================================
# çŠ¶æ€æ£€æŸ¥
# ============================================================
api_key = ""
try:
    api_key = st.secrets.get("DEEPSEEK_API_KEY", "")
except Exception:
    pass
has_api = bool(api_key and not api_key.startswith("sk-xxxx"))
has_tushare = _tushare_available()

col_s1, col_s2 = st.columns(2)
with col_s1:
    if has_api:
        st.success("ğŸ¤– DeepSeek AI: å·²è¿æ¥")
    else:
        st.error("ğŸ¤– DeepSeek AI: æœªé…ç½®")
with col_s2:
    if has_tushare:
        st.success("ğŸ“¡ Tushare PRO: å·²è¿æ¥ (ä¸»åŠ›æ•°æ®æº)")
    else:
        st.warning("ğŸ“¡ Tushare PRO: æœªé…ç½® (é™çº§è‡³ AKShare)")

if not has_api:
    st.warning("""
âš ï¸ **æœªé…ç½® DeepSeek API Key** â€” CIO æ—¥æŠ¥éœ€è¦ AI

1. æ³¨å†Œ [platform.deepseek.com](https://platform.deepseek.com/)
2. åˆ›å»º API Key
3. Streamlit Cloud â†’ Settings â†’ Secrets:
```
DEEPSEEK_API_KEY = "sk-ä½ çš„å¯†é’¥"
```
    """)

st.divider()

# ============================================================
# ç¼“å­˜
# ============================================================
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "data")
os.makedirs(DATA_DIR, exist_ok=True)
today_file = os.path.join(DATA_DIR, f"report_{datetime.now().strftime('%Y%m%d')}.json")


def load_cache():
    if os.path.exists(today_file):
        with open(today_file, "r", encoding="utf-8") as f:
            return json.load(f)
    return None


def save_cache(data):
    with open(today_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)


cached = load_cache()
if cached:
    st.info(f"ğŸ“„ å·²æœ‰ä»Šæ—¥ç¼“å­˜ï¼ˆ{cached.get('time', '')}ï¼‰Â· æ•°æ®ç»´åº¦: {cached.get('data_dimensions', '?')} Â· æ•°æ®æº: {cached.get('data_sources', '?')}")

# ============================================================
# æŒ‰é’®
# ============================================================
c1, c2 = st.columns(2)
with c1:
    gen_btn = st.button("ğŸš€ ç”Ÿæˆæ–°æŠ¥å‘Š", type="primary", use_container_width=True, disabled=not has_api)
with c2:
    load_btn = st.button("ğŸ“„ æŸ¥çœ‹ç¼“å­˜æŠ¥å‘Š", use_container_width=True, disabled=not cached)

report = None

# ============================================================
# ç”ŸæˆæŠ¥å‘Š
# ============================================================
if gen_btn and has_api:
    progress = st.progress(0, "å‡†å¤‡ä¸­...")

    # Stage 1: å…¨é‡æ•°æ®é‡‡é›†
    progress.progress(10, "ğŸ“¡ é‡‡é›†å…¨é‡æ•°æ®: è¡Œæƒ…+å®è§‚+æµåŠ¨æ€§+ä¿¡ç”¨+æ³¢åŠ¨ç‡+èµ„é‡‘+æœŸè´§+èµ„è®¯+ç ”æŠ¥...")
    data_pack = get_daily_data_pack()

    # æ•°æ®è´¨é‡å®¡è®¡
    data_audit = []
    dim_count = 0
    if data_pack.get("indices") is not None and not data_pack["indices"].empty:
        data_audit.append("âœ…æŒ‡æ•°")
        dim_count += 1
    else:
        data_audit.append("âŒæŒ‡æ•°")
    if data_pack.get("overview"):
        data_audit.append("âœ…æ¶¨è·Œ")
        dim_count += 1
    else:
        data_audit.append("âŒæ¶¨è·Œ")
    if data_pack.get("macro"):
        data_audit.append(f"âœ…å®è§‚({len(data_pack['macro'])}é¡¹)")
        dim_count += 1
    else:
        data_audit.append("âŒå®è§‚")
    if data_pack.get("liquidity"):
        data_audit.append(f"âœ…æµåŠ¨æ€§({len(data_pack['liquidity'])}é¡¹)")
        dim_count += 1
    else:
        data_audit.append("âš ï¸æµåŠ¨æ€§(ç¼º)")
    if data_pack.get("credit"):
        data_audit.append("âœ…ä¿¡ç”¨")
        dim_count += 1
    else:
        data_audit.append("âš ï¸ä¿¡ç”¨(ç¼º)")
    if data_pack.get("style"):
        data_audit.append(f"âœ…é£æ ¼({len(data_pack['style'])}é¡¹)")
        dim_count += 1
    else:
        data_audit.append("âŒé£æ ¼")
    if data_pack.get("volatility"):
        data_audit.append("âœ…æ³¢åŠ¨ç‡")
        dim_count += 1
    else:
        data_audit.append("âš ï¸æ³¢åŠ¨ç‡(ç¼º)")
    if data_pack.get("northbound"):
        data_audit.append("âœ…åŒ—å‘")
        dim_count += 1
    else:
        data_audit.append("âš ï¸åŒ—å‘(ç¼º)")
    if data_pack.get("margin"):
        data_audit.append("âœ…èèµ„")
        dim_count += 1
    else:
        data_audit.append("âš ï¸èèµ„(ç¼º)")
    if data_pack.get("futures"):
        data_audit.append(f"âœ…æœŸè´§({len(data_pack['futures'])}å“ç§)")
        dim_count += 1
    else:
        data_audit.append("âš ï¸æœŸè´§(ç¼º)")
    if data_pack.get("news"):
        data_audit.append(f"âœ…èµ„è®¯({len(data_pack['news'])}æ¡)")
        dim_count += 1
    else:
        data_audit.append("âŒèµ„è®¯")
    if data_pack.get("research"):
        data_audit.append(f"âœ…ç ”æŠ¥({len(data_pack['research'])}æ¡)")
        dim_count += 1
    else:
        data_audit.append("âš ï¸ç ”æŠ¥(ç¼º)")

    progress.progress(40, f"ğŸ“Š æ•°æ®å®¡è®¡å®Œæˆ: {dim_count}/12 ç»´åº¦ | {' '.join(data_audit)}")

    # Stage 2: æ•°æ®æ‰“åŒ…
    progress.progress(50, "ğŸ“¦ æ•°æ®æ‰“åŒ… (æ¡¥æ°´å››ç»´ + å…¨é‡å¸‚åœº)...")
    market_text = pack_market_text(data_pack)
    news_text = pack_news_text(data_pack)

    # æ˜¾ç¤ºæ•°æ®è¾“å…¥è§„æ¨¡
    total_chars = len(market_text) + len(news_text)
    st.caption(f"ğŸ“ AI è¾“å…¥è§„æ¨¡: å¸‚åœºæ•°æ® {len(market_text)} å­— + èµ„è®¯ {len(news_text)} å­— = {total_chars} å­—")

    # Stage 3: AI ç”Ÿæˆ
    progress.progress(60, "ğŸ¤– DeepSeek æ­£åœ¨ç”Ÿæˆ CIO é…ç½®æŠ¥å‘Š (æ¡¥æ°´å››ç»´æ¡†æ¶)...")
    report = generate_daily_report(market_text, news_text)

    # Stage 4: ä¿å­˜
    progress.progress(90, "ğŸ’¾ ä¿å­˜...")
    data_sources = "Tushare PRO (ä¸») + AKShare (è¾…)" if has_tushare else "AKShare"
    save_cache({
        "time": datetime.now().strftime("%H:%M"),
        "report": report,
        "data_sources": data_sources,
        "data_dimensions": dim_count,
        "data_audit": data_audit,
        "market_text_preview": market_text[:800],
        "news_count": len(data_pack.get("news", [])),
        "research_count": len(data_pack.get("research", [])),
        "input_chars": total_chars,
    })

    progress.progress(100, "âœ… å®Œæˆ!")
    st.balloons()

elif load_btn and cached:
    report = cached.get("report", "")

# ============================================================
# å±•ç¤ºæŠ¥å‘Š
# ============================================================
if report:
    st.divider()

    st.markdown(f"""
<div style="padding:16px 20px; border-radius:10px;
background: linear-gradient(135deg, rgba(255,107,53,0.12), rgba(69,183,209,0.06));
border: 1px solid rgba(255,107,53,0.25); margin-bottom:20px;">
<h2 style="margin:0; color:#FF6B35;">ğŸ”­ å¯»æ˜Ÿ FOF CIO æ—¥æŠ¥</h2>
<p style="margin:4px 0 0; color:#999;">{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')} Â· DeepSeek V3 Â· æ¡¥æ°´å››ç»´æ¡†æ¶ Â· æ•°æ®æº: {'Tushare PRO + AKShare' if has_tushare else 'AKShare'}</p>
</div>""", unsafe_allow_html=True)

    st.markdown(report)
    st.divider()

    c1, c2 = st.columns(2)
    with c1:
        st.download_button(
            "ğŸ“„ ä¸‹è½½ Markdown",
            report,
            f"å¯»æ˜ŸCIOæ—¥æŠ¥_{datetime.now().strftime('%Y%m%d')}.md",
            "text/markdown",
            use_container_width=True,
        )
    with c2:
        st.download_button(
            "ğŸ“ ä¸‹è½½ TXT",
            report.replace("###", "").replace("**", ""),
            f"å¯»æ˜ŸCIOæ—¥æŠ¥_{datetime.now().strftime('%Y%m%d')}.txt",
            "text/plain",
            use_container_width=True,
        )

    with st.expander("ğŸ” æ•°æ®è´¨é‡å®¡è®¡"):
        if cached:
            st.markdown(f"- æ•°æ®ç»´åº¦: **{cached.get('data_dimensions', '?')}/12**")
            audit = cached.get("data_audit", [])
            if audit:
                st.markdown(f"- è¯¦æƒ…: {' | '.join(audit)}")
            st.markdown(f"- èµ„è®¯: {cached.get('news_count', '?')} æ¡")
            st.markdown(f"- ç ”æŠ¥: {cached.get('research_count', '?')} æ¡")
            st.markdown(f"- AIè¾“å…¥: {cached.get('input_chars', '?')} å­—")
            st.markdown(f"- æ•°æ®æº: {cached.get('data_sources', '?')}")
            if cached.get("market_text_preview"):
                st.text(cached["market_text_preview"])

else:
    if not gen_btn:
        st.markdown("""
### ğŸ“‹ V4 æŠ¥å‘ŠåŒ…å«ä»¥ä¸‹å†³ç­–æ¨¡å—

| æ¨¡å— | å†…å®¹ | æ•°æ®ä¾æ® |
|------|------|---------|
| **ä¸€ã€å®è§‚å‘¨æœŸ** | æ¡¥æ°´å››ç»´: å¢é•¿/é€šèƒ€/æµåŠ¨æ€§/ä¿¡ç”¨ | PMI/CPI/PPI/M2/Shibor/ç¤¾è/ä¿¡ç”¨åˆ©å·® |
| **äºŒã€å¤§ç±»é…ç½®** | æƒç›Š/å›ºæ”¶/å•†å“/ç°é‡‘ = 100% | å®è§‚å‘¨æœŸå®šä½ + ç¾æ—æ—¶é’Ÿ |
| **ä¸‰ã€FOFç­–ç•¥** | 7ç­–ç•¥æƒé‡ = 100% | æ³¢åŠ¨ç‡/é£æ ¼/é‡èƒ½ â†’ ç­–ç•¥é€‚é… |
| **å››ã€é£æ ¼è¡Œä¸š** | å¤§å°ç›˜+æˆé•¿ä»·å€¼+TOP3è¡Œä¸š | 5æ—¥+20æ—¥åŠ¨é‡ + èµ„é‡‘æµå‘ |
| **äº”ã€å·¥å…·ç®±** | ETFä»£ç  + ä¸ªè‚¡çº¿ç´¢ | è¡Œä¸šå‚¬åŒ–å‰‚ + ç ”æŠ¥è¯„çº§ |
| **å…­ã€é£é™©é¢„è­¦** | 3å¤§é£é™© + å¯¹å†²é¢„æ¡ˆ | æ³¢åŠ¨ç‡ + æƒ…ç»ªæ¸©åº¦ + èµ„é‡‘ |
| **ä¸ƒã€æ•°æ®è‡ªæ£€** | æ•°æ®å®Œæ•´æ€§å®¡è®¡ | 12ç»´æ•°æ®è¦†ç›–ç‡ |

ğŸ‘† ç‚¹å‡» **ã€Œç”Ÿæˆæ–°æŠ¥å‘Šã€** å¼€å§‹

**æ•°æ®æ¶æ„**: Tushare PRO (ä¸») â†’ AKShare (é™çº§å…œåº•) Â· 12+ æ•°æ®ç»´åº¦å…¨é‡è¾“å…¥
        """)

st.divider()
st.caption(f"å¯»æ˜Ÿé…ç½®è·Ÿè¸ªç³»ç»Ÿ Â· V4 Â· {datetime.now().strftime('%H:%M:%S')}")
